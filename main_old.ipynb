{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c2b7e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Import th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d348eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Vietnamese NLP Functions\n",
    "class VietnameseNLP:\n",
    "    def __init__(self):\n",
    "        self.stopwords = {\n",
    "            'v√†', 'c·ªßa', 'c√≥', 'l√†', 'trong', 'v·ªõi', 'ƒë∆∞·ª£c', 'cho', 't·ª´', 'c√°c', 'm·ªôt', 'nh·ªØng',\n",
    "            'n√†y', 'ƒë√≥', 'khi', 'ƒë·ªÉ', 'kh√¥ng', 'v·ªÅ', 'sau', 'tr∆∞·ªõc', 'hay', 'ho·∫∑c', 'n·∫øu', 'nh∆∞'\n",
    "        }\n",
    "        \n",
    "    def normalize_vietnamese(self, text):\n",
    "        return text.lower() if isinstance(text, str) else \"\"\n",
    "    \n",
    "    def remove_stopwords(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        words = text.split()\n",
    "        filtered_words = [word for word in words if word not in self.stopwords]\n",
    "        return ' '.join(filtered_words)\n",
    "    \n",
    "    def clean_text_advanced(self, text, remove_stopwords=True, normalize=True):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        text = re.sub(r'[^\\w\\s√†√°·∫°·∫£√£√¢·∫ß·∫•·∫≠·∫©·∫´ƒÉ·∫±·∫Ø·∫∑·∫≥·∫µ√®√©·∫π·∫ª·∫Ω√™·ªÅ·∫ø·ªá·ªÉ·ªÖ√¨√≠·ªã·ªâƒ©√≤√≥·ªç·ªè√µ√¥·ªì·ªë·ªô·ªï·ªó∆°·ªù·ªõ·ª£·ªü·ª°√π√∫·ª•·ªß≈©∆∞·ª´·ª©·ª±·ª≠·ªØ·ª≥√Ω·ªµ·ª∑·ªπƒë]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        if normalize:\n",
    "            text = self.normalize_vietnamese(text)\n",
    "        if remove_stopwords:\n",
    "            text = self.remove_stopwords(text)\n",
    "        return text\n",
    "\n",
    "def clean_vietnamese_text(text, remove_stopwords=True, normalize=True):\n",
    "    nlp = VietnameseNLP()\n",
    "    return nlp.clean_text_advanced(text, remove_stopwords, normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e325e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Utility Functions\n",
    "def convert_latex_to_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    text = text.replace('\\\\n', '\\n')\n",
    "    replacements = {\n",
    "        r'\\\\frac\\{([^}]+)\\}\\{([^}]+)\\}': r'(\\1)/(\\2)',\n",
    "        r'\\^{([^}]+)}': r'^(\\1)',\n",
    "        r'_{([^}]+)}': r'_(\\1)',\n",
    "        r'\\\\times': '√ó', r'\\\\div': '√∑', r'\\\\pm': '¬±',\n",
    "    }\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    return text.strip()\n",
    "\n",
    "def parse_question(question_full):\n",
    "    lines = question_full.split('\\n')\n",
    "    question = lines[0]\n",
    "    if question.startswith('C√¢u'):\n",
    "        question = re.sub(r'^C√¢u \\d+:\\s*', '', question)\n",
    "    \n",
    "    options = []\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        if line and line.startswith(('A.', 'B.', 'C.', 'D.')):\n",
    "            options.append(line)\n",
    "    \n",
    "    return question.strip(), options\n",
    "\n",
    "class ScoreTracker:\n",
    "    def __init__(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def add_result(self, is_correct):\n",
    "        self.total += 1\n",
    "        if is_correct:\n",
    "            self.correct += 1\n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        return (self.correct / self.total * 100) if self.total > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c82c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ƒê√£ t·∫£i 600 c√¢u h·ªèi\n",
      "üìã C·ªôt d·ªØ li·ªáu: ['id', 'question', 'options', 'answer', 'subject', 'explanation']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Load d·ªØ li·ªáu VNHSGE\n",
    "def load_vnhsge_data(data_folder='Dataset'):\n",
    "    subjects = ['Biology', 'Chemistry', 'Physics']\n",
    "    all_data = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "        subject_path = os.path.join(data_folder, subject)\n",
    "        if not os.path.exists(subject_path):\n",
    "            continue\n",
    "            \n",
    "        json_files = glob.glob(os.path.join(subject_path, \"*.json\"))\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                for item in data:\n",
    "                    if 'Question' in item and 'Choice' in item:\n",
    "                        question_text, options = parse_question(item['Question'])\n",
    "                        \n",
    "                        question_data = {\n",
    "                            'id': item.get('ID', ''),\n",
    "                            'question': question_text,\n",
    "                            'options': options,\n",
    "                            'answer': item['Choice'],\n",
    "                            'subject': subject.lower(),\n",
    "                            'explanation': convert_latex_to_text(item.get('Explanation', ''))\n",
    "                        }\n",
    "                        all_data.append(question_data)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "raw_data = load_vnhsge_data()\n",
    "print(f\"üìä ƒê√£ t·∫£i {len(raw_data)} c√¢u h·ªèi\")\n",
    "print(f\"üìã C·ªôt d·ªØ li·ªáu: {raw_data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272149f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà TH·ªêNG K√ä D·ªÆ LI·ªÜU:\n",
      "T·ªïng s·ªë c√¢u h·ªèi: 600\n",
      "S·ªë m√¥n h·ªçc: 3\n",
      "\n",
      "üìä Ph√¢n ph·ªëi theo m√¥n:\n",
      "subject\n",
      "biology      200\n",
      "chemistry    200\n",
      "physics      200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîç M·∫´u d·ªØ li·ªáu:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MET_Bio_IE_2019_1</td>\n",
       "      <td>C√≥ th·ªÉ s·ª≠ d·ª•ng h√≥a ch·∫•t n√†o sau ƒë√¢y ƒë·ªÉ ph√°t hi...</td>\n",
       "      <td>[A. Dung d·ªãch NaCl., B. Dung d·ªãch Ca(OH)2., C....</td>\n",
       "      <td>B</td>\n",
       "      <td>biology</td>\n",
       "      <td>C√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng Ca(OH)2 ƒë·ªÉ ph√°t hi·ªán qu√° t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MET_Bio_IE_2019_2</td>\n",
       "      <td>ƒê·ªông v·∫≠t n√†o sau ƒë√¢y trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªù...</td>\n",
       "      <td>[A. Ch√¢u ch·∫•u., B. S∆∞ t·ª≠., C. Chu·ªôt., D. ·∫æch ƒë...</td>\n",
       "      <td>A</td>\n",
       "      <td>biology</td>\n",
       "      <td>Ch√¢u ch·∫•u trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªùng th√¥ng qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MET_Bio_IE_2019_3</td>\n",
       "      <td>Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ n√†o ...</td>\n",
       "      <td>[A. ADN., B. mARN., C. tARN., D. Pr√¥t√™in.]</td>\n",
       "      <td>D</td>\n",
       "      <td>biology</td>\n",
       "      <td>Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ Pr√¥t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MET_Bio_IE_2019_4</td>\n",
       "      <td>Ph√¢n t·ª≠ n√†o sau ƒë√¢y tr·ª±c ti·∫øp l√†m khu√¥n cho qu...</td>\n",
       "      <td>[A. ADN., B. mARN., C. tARN., D. rARN.]</td>\n",
       "      <td>B</td>\n",
       "      <td>biology</td>\n",
       "      <td>Ph√¢n t·ª≠ mARM tr·ª±c ti·∫øp l√†m khu√¥n cho qu√° tr√¨nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MET_Bio_IE_2019_5</td>\n",
       "      <td>M·ªôt ph√¢n t·ª≠ ADN ·ªü vi khu·∫©n c√≥ 10% s·ªë nucl√™√¥tit...</td>\n",
       "      <td>[A. 10%., B. 30%., C. 20%., D. 40%.]</td>\n",
       "      <td>D</td>\n",
       "      <td>biology</td>\n",
       "      <td>Theo nguy√™n t·∫Øc b·ªï sung A = T, G = X n√™n %A +%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           question  \\\n",
       "0  MET_Bio_IE_2019_1  C√≥ th·ªÉ s·ª≠ d·ª•ng h√≥a ch·∫•t n√†o sau ƒë√¢y ƒë·ªÉ ph√°t hi...   \n",
       "1  MET_Bio_IE_2019_2  ƒê·ªông v·∫≠t n√†o sau ƒë√¢y trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªù...   \n",
       "2  MET_Bio_IE_2019_3  Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ n√†o ...   \n",
       "3  MET_Bio_IE_2019_4  Ph√¢n t·ª≠ n√†o sau ƒë√¢y tr·ª±c ti·∫øp l√†m khu√¥n cho qu...   \n",
       "4  MET_Bio_IE_2019_5  M·ªôt ph√¢n t·ª≠ ADN ·ªü vi khu·∫©n c√≥ 10% s·ªë nucl√™√¥tit...   \n",
       "\n",
       "                                             options answer  subject  \\\n",
       "0  [A. Dung d·ªãch NaCl., B. Dung d·ªãch Ca(OH)2., C....      B  biology   \n",
       "1  [A. Ch√¢u ch·∫•u., B. S∆∞ t·ª≠., C. Chu·ªôt., D. ·∫æch ƒë...      A  biology   \n",
       "2         [A. ADN., B. mARN., C. tARN., D. Pr√¥t√™in.]      D  biology   \n",
       "3            [A. ADN., B. mARN., C. tARN., D. rARN.]      B  biology   \n",
       "4               [A. 10%., B. 30%., C. 20%., D. 40%.]      D  biology   \n",
       "\n",
       "                                         explanation  \n",
       "0  C√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng Ca(OH)2 ƒë·ªÉ ph√°t hi·ªán qu√° t...  \n",
       "1  Ch√¢u ch·∫•u trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªùng th√¥ng qu...  \n",
       "2  Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ Pr√¥t...  \n",
       "3  Ph√¢n t·ª≠ mARM tr·ª±c ti·∫øp l√†m khu√¥n cho qu√° tr√¨nh...  \n",
       "4  Theo nguy√™n t·∫Øc b·ªï sung A = T, G = X n√™n %A +%...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 5 - Ph√¢n t√≠ch d·ªØ li·ªáu c∆° b·∫£n\n",
    "print(\"üìà TH·ªêNG K√ä D·ªÆ LI·ªÜU:\")\n",
    "print(f\"T·ªïng s·ªë c√¢u h·ªèi: {len(raw_data)}\")\n",
    "print(f\"S·ªë m√¥n h·ªçc: {raw_data['subject'].nunique()}\")\n",
    "print(\"\\nüìä Ph√¢n ph·ªëi theo m√¥n:\")\n",
    "print(raw_data['subject'].value_counts())\n",
    "\n",
    "print(\"\\nüîç M·∫´u d·ªØ li·ªáu:\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad2b8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU:\n",
      "Null values:\n",
      "id             0\n",
      "question       0\n",
      "options        0\n",
      "answer         0\n",
      "subject        0\n",
      "explanation    0\n",
      "dtype: int64\n",
      "\n",
      "üìè ƒê·ªô d√†i c√¢u h·ªèi:\n",
      "Trung b√¨nh: 167.3 k√Ω t·ª±\n",
      "Min: 21, Max: 754\n",
      "\n",
      "üìù Ph√¢n ph·ªëi ƒë√°p √°n:\n",
      "answer\n",
      "A    188\n",
      "C    144\n",
      "B    140\n",
      "D    128\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 - Ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu\n",
    "print(\"üîç KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG D·ªÆ LI·ªÜU:\")\n",
    "print(f\"Null values:\")\n",
    "print(raw_data.isnull().sum())\n",
    "\n",
    "print(f\"\\nüìè ƒê·ªô d√†i c√¢u h·ªèi:\")\n",
    "question_lengths = raw_data['question'].str.len()\n",
    "print(f\"Trung b√¨nh: {question_lengths.mean():.1f} k√Ω t·ª±\")\n",
    "print(f\"Min: {question_lengths.min()}, Max: {question_lengths.max()}\")\n",
    "\n",
    "print(f\"\\nüìù Ph√¢n ph·ªëi ƒë√°p √°n:\")\n",
    "print(raw_data['answer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5104365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - DifficultyClassifier Class\n",
    "class DifficultyClassifier:\n",
    "    def __init__(self):\n",
    "        self.text_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2), min_df=2, max_df=0.9)\n",
    "        self.model = RandomForestClassifier(n_estimators=50, max_depth=8, random_state=42, n_jobs=-1)\n",
    "        self.is_trained = False\n",
    "        self.evaluation_results = {}\n",
    "    \n",
    "    def _extract_features(self, question_text, options_text):\n",
    "        full_text = question_text + \" \" + options_text\n",
    "        full_lower = full_text.lower()\n",
    "        \n",
    "        patterns = {\n",
    "            'analysis': ['ph√¢n t√≠ch', 'so s√°nh', 'ƒë√°nh gi√°', 'gi·∫£i th√≠ch'],\n",
    "            'calculation': ['t√≠nh', 'to√°n', 'c√¥ng th·ª©c', 'mol', 'gam'],\n",
    "            'synthesis': ['t·ªïng h·ª£p', 'ph·∫£n ·ª©ng', 'c∆° ch·∫ø', 'qu√° tr√¨nh'],\n",
    "            'evaluation': ['·∫£nh h∆∞·ªüng', 't√°c ƒë·ªông', 'nguy√™n nh√¢n'],\n",
    "            'definition': ['l√† g√¨', 't√™n g·ªçi', 'thu·ªôc'],\n",
    "            'identification': ['m√†u', 'tr·∫°ng th√°i', 't√≠nh ch·∫•t']\n",
    "        }\n",
    "        \n",
    "        features = []\n",
    "        for category in ['analysis', 'calculation', 'synthesis', 'evaluation', 'definition', 'identification']:\n",
    "            count = sum(1 for word in patterns[category] if word in full_lower)\n",
    "            features.append(count)\n",
    "        \n",
    "        features.extend([\n",
    "            len(question_text.split()),\n",
    "            len(options_text.split()),\n",
    "            full_text.count('.'),\n",
    "            sum(1 for c in full_text if c in '+-*/=()$^_'),\n",
    "            sum(1 for c in full_text if c.isupper()),\n",
    "            sum(1 for w in full_text.split() if len(w) > 8)\n",
    "        ])\n",
    "        \n",
    "        features.extend([\n",
    "            1 if 't·∫°i sao' in full_lower or 'v√¨ sao' in full_lower else 0,\n",
    "            1 if 'nh∆∞ th·∫ø n√†o' in full_lower else 0,\n",
    "            1 if 'bao nhi√™u' in full_lower else 0\n",
    "        ])\n",
    "        \n",
    "        return np.array(features).reshape(1, -1)\n",
    "    \n",
    "    def _create_labels(self, data):\n",
    "        difficulties = []\n",
    "        for _, row in data.iterrows():\n",
    "            options_text = ' '.join(row['options']) if row['options'] else ''\n",
    "            features = self._extract_features(row['question'], options_text).flatten()\n",
    "            \n",
    "            score = (features[0] + features[1] + features[2]) * 2\n",
    "            score -= (features[4] + features[5])\n",
    "            score += features[6] * 0.1 + features[9] * 0.2\n",
    "            score += features[12] + features[13] * 2\n",
    "            \n",
    "            if score <= 2:\n",
    "                difficulty = 'easy'\n",
    "            elif score <= 5:\n",
    "                difficulty = 'medium'\n",
    "            else:\n",
    "                difficulty = 'hard'\n",
    "            \n",
    "            difficulties.append(difficulty)\n",
    "        \n",
    "        return difficulties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb391403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ ƒêang t·∫°o nh√£n ƒë·ªô kh√≥...\n",
      "üìä PH√ÇN PH·ªêI ƒê·ªò KH√ì:\n",
      "hard      282\n",
      "medium    202\n",
      "easy      116\n",
      "Name: count, dtype: int64\n",
      "\n",
      "T·ª∑ l·ªá ph·∫ßn trƒÉm:\n",
      "hard      47.0\n",
      "medium    33.7\n",
      "easy      19.3\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 - Kh·ªüi t·∫°o v√† train DifficultyClassifier\n",
    "difficulty_classifier = DifficultyClassifier()\n",
    "print(\"ü§ñ ƒêang t·∫°o nh√£n ƒë·ªô kh√≥...\")\n",
    "difficulties = difficulty_classifier._create_labels(raw_data)\n",
    "\n",
    "print(\"üìä PH√ÇN PH·ªêI ƒê·ªò KH√ì:\")\n",
    "difficulty_counts = pd.Series(difficulties).value_counts()\n",
    "print(difficulty_counts)\n",
    "print(f\"\\nT·ª∑ l·ªá ph·∫ßn trƒÉm:\")\n",
    "print((difficulty_counts / len(difficulties) * 100).round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d060ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PH√ÇN T√çCH FEATURES CHO ƒê·ªò KH√ì:\n",
      "C√¢u 1: medium - Features: [0 0 1 0 0 0]\n",
      "C√¢u 2: easy - Features: [0 0 0 0 0 0]\n",
      "C√¢u 3: easy - Features: [0 0 0 0 0 0]\n",
      "C√¢u 4: medium - Features: [0 0 1 0 0 0]\n",
      "C√¢u 5: medium - Features: [0 0 0 0 0 0]\n",
      "C√¢u 6: easy - Features: [0 0 0 0 0 0]\n",
      "C√¢u 7: medium - Features: [0 0 0 0 0 0]\n",
      "C√¢u 8: easy - Features: [0 0 0 0 0 0]\n",
      "C√¢u 9: medium - Features: [0 0 0 0 0 0]\n",
      "C√¢u 10: medium - Features: [0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 - Ph√¢n t√≠ch features cho ƒë·ªô kh√≥\n",
    "print(\"üîç PH√ÇN T√çCH FEATURES CHO ƒê·ªò KH√ì:\")\n",
    "sample_questions = raw_data.head(10)\n",
    "for i, (_, row) in enumerate(sample_questions.iterrows()):\n",
    "    options_text = ' '.join(row['options']) if row['options'] else ''\n",
    "    features = difficulty_classifier._extract_features(row['question'], options_text).flatten()\n",
    "    print(f\"C√¢u {i+1}: {difficulties[i]} - Features: {features[:6]}\")  # Show first 6 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a621c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ K·∫æT QU·∫¢ DIFFICULTY CLASSIFICATION:\n",
      "Accuracy: 0.6583\n",
      "F1-Score: 0.6199\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 - Train difficulty model v·ªõi evaluation\n",
    "texts = []\n",
    "for _, row in raw_data.iterrows():\n",
    "    options_text = ' '.join(row['options']) if row['options'] else ''\n",
    "    full_text = row['question'] + ' ' + options_text\n",
    "    processed_text = clean_vietnamese_text(full_text, remove_stopwords=True, normalize=True)\n",
    "    texts.append(processed_text)\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    texts, difficulties, test_size=0.2, random_state=42, stratify=difficulties\n",
    ")\n",
    "\n",
    "X_train_vec = difficulty_classifier.text_vectorizer.fit_transform(X_train_text)\n",
    "X_test_vec = difficulty_classifier.text_vectorizer.transform(X_test_text)\n",
    "\n",
    "difficulty_classifier.model.fit(X_train_vec, y_train)\n",
    "y_pred = difficulty_classifier.model.predict(X_test_vec)\n",
    "\n",
    "print(\"üéØ K·∫æT QU·∫¢ DIFFICULTY CLASSIFICATION:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf44afab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CONFUSION MATRIX - DIFFICULTY:\n",
      "            easy    hard  medium\n",
      "    easy       3       3      17\n",
      "    hard       0      50       7\n",
      "  medium       0      14      26\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 - Confusion Matrix cho Difficulty\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "labels = sorted(list(set(y_test) | set(y_pred)))\n",
    "\n",
    "print(\"üìä CONFUSION MATRIX - DIFFICULTY:\")\n",
    "print(f\"{'':>8}\", end=\"\")\n",
    "for label in labels:\n",
    "    print(f\"{label:>8}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, true_label in enumerate(labels):\n",
    "    print(f\"{true_label:>8}\", end=\"\")\n",
    "    for j in range(len(labels)):\n",
    "        print(f\"{cm[i][j]:>8}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a3625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã CLASSIFICATION REPORT - DIFFICULTY:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        easy       1.00      0.13      0.23        23\n",
      "        hard       0.75      0.88      0.81        57\n",
      "      medium       0.52      0.65      0.58        40\n",
      "\n",
      "    accuracy                           0.66       120\n",
      "   macro avg       0.76      0.55      0.54       120\n",
      "weighted avg       0.72      0.66      0.62       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 - Classification Report cho Difficulty\n",
    "print(\"üìã CLASSIFICATION REPORT - DIFFICULTY:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1da4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13 - TopicClassifier Class\n",
    "class TopicClassifier:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=2000, ngram_range=(1, 3), min_df=2, max_df=0.8)\n",
    "        self.model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "        self.label_to_id = {}\n",
    "        self.id_to_label = {}\n",
    "        self.is_trained = False\n",
    "        \n",
    "        self.subject_topics = {\n",
    "            'physics': ['Dao ƒë·ªông c∆°', 'S√≥ng c∆°', 'ƒêi·ªán xoay chi·ªÅu', 'T·ª´ tr∆∞·ªùng', 'ƒêi·ªán tr∆∞·ªùng', 'Quang h·ªçc', 'C∆° h·ªçc', 'Nhi·ªát h·ªçc'],\n",
    "            'chemistry': ['H√≥a h·ªØu c∆°', 'Este ‚Äì Lipit', 'ƒêi·ªán ph√¢n', 'C√¢n b·∫±ng h√≥a h·ªçc', 'Axit - Baz∆°', 'Oxi h√≥a - Kh·ª≠', 'Polime', 'Kim lo·∫°i'],\n",
    "            'biology': ['Di truy·ªÅn h·ªçc', 'Ti·∫øn h√≥a', 'Sinh th√°i h·ªçc', 'T·∫ø b√†o h·ªçc', 'Sinh l√Ω h·ªçc', 'Ph√¢n lo·∫°i sinh v·∫≠t', 'Sinh h·ªçc ph√¢n t·ª≠', 'Mi·ªÖn d·ªãch h·ªçc']\n",
    "        }\n",
    "    \n",
    "    def _create_topic_labels(self, data):\n",
    "        topic_keywords = {\n",
    "            'Dao ƒë·ªông c∆°': ['dao ƒë·ªông', 'chu k·ª≥', 't·∫ßn s·ªë', 'bi√™n ƒë·ªô', 'con l·∫Øc', 'l√≤ xo'],\n",
    "            'ƒêi·ªán xoay chi·ªÅu': ['xoay chi·ªÅu', 'ƒëi·ªán √°p hi·ªáu d·ª•ng', 'd√≤ng ƒëi·ªán xoay chi·ªÅu', 'm√°y bi·∫øn √°p'],\n",
    "            'H√≥a h·ªØu c∆°': ['ankan', 'anken', 'ankin', 'benzen', 'ancol', 'phenol', 'carbon'],\n",
    "            'Di truy·ªÅn h·ªçc': ['gen', 'alen', 'NST', 'nhi·ªÖm s·∫Øc th·ªÉ', 'ADN', 'ARN', 'ƒë·ªôt bi·∫øn', 'lai']\n",
    "        }\n",
    "        \n",
    "        topics = []\n",
    "        for _, row in data.iterrows():\n",
    "            subject = row['subject']\n",
    "            question_text = row['question'].lower()\n",
    "            \n",
    "            subject_topic_list = self.subject_topics.get(subject, [])\n",
    "            best_topic = 'Kh√°c'\n",
    "            max_score = 0\n",
    "            \n",
    "            for topic in subject_topic_list:\n",
    "                if topic in topic_keywords:\n",
    "                    keywords = topic_keywords[topic]\n",
    "                    score = sum(1 for keyword in keywords if keyword in question_text)\n",
    "                    \n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "                        best_topic = topic\n",
    "            \n",
    "            if best_topic == 'Kh√°c':\n",
    "                if subject == 'physics':\n",
    "                    best_topic = 'C∆° h·ªçc'\n",
    "                elif subject == 'chemistry':\n",
    "                    best_topic = 'H√≥a h·ªØu c∆°'\n",
    "                elif subject == 'biology':\n",
    "                    best_topic = 'T·∫ø b√†o h·ªçc'\n",
    "            \n",
    "            topics.append(best_topic)\n",
    "        \n",
    "        return topics\n",
    "    \n",
    "    def get_topics_by_subject(self, subject):\n",
    "        return self.subject_topics.get(subject, ['Kh√°c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e79c9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è ƒêang t·∫°o nh√£n ch·ªß ƒë·ªÅ...\n",
      "üìä PH√ÇN PH·ªêI CH·ª¶ ƒê·ªÄ:\n",
      "H√≥a h·ªØu c∆°         200\n",
      "C∆° h·ªçc             103\n",
      "T·∫ø b√†o h·ªçc         100\n",
      "Di truy·ªÅn h·ªçc      100\n",
      "Dao ƒë·ªông c∆°         72\n",
      "ƒêi·ªán xoay chi·ªÅu     25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 - Kh·ªüi t·∫°o v√† train TopicClassifier\n",
    "topic_classifier = TopicClassifier()\n",
    "print(\"üè∑Ô∏è ƒêang t·∫°o nh√£n ch·ªß ƒë·ªÅ...\")\n",
    "topics = topic_classifier._create_topic_labels(raw_data)\n",
    "\n",
    "print(\"üìä PH√ÇN PH·ªêI CH·ª¶ ƒê·ªÄ:\")\n",
    "topic_counts = pd.Series(topics).value_counts()\n",
    "print(topic_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "393d1406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã CH·ª¶ ƒê·ªÄ THEO M√îN H·ªåC:\n",
      "\n",
      "PHYSICS:\n",
      "topic\n",
      "C∆° h·ªçc             103\n",
      "Dao ƒë·ªông c∆°         72\n",
      "ƒêi·ªán xoay chi·ªÅu     25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CHEMISTRY:\n",
      "topic\n",
      "H√≥a h·ªØu c∆°    200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "BIOLOGY:\n",
      "topic\n",
      "T·∫ø b√†o h·ªçc       100\n",
      "Di truy·ªÅn h·ªçc    100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 15 - Ph√¢n t√≠ch topics theo subject\n",
    "print(\"üìã CH·ª¶ ƒê·ªÄ THEO M√îN H·ªåC:\")\n",
    "data_with_topics = raw_data.copy()\n",
    "data_with_topics['topic'] = topics\n",
    "\n",
    "for subject in ['physics', 'chemistry', 'biology']:\n",
    "    subject_data = data_with_topics[data_with_topics['subject'] == subject]\n",
    "    print(f\"\\n{subject.upper()}:\")\n",
    "    print(subject_data['topic'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9538307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ K·∫æT QU·∫¢ TOPIC CLASSIFICATION:\n",
      "Accuracy: 0.8667\n",
      "F1-Score: 0.8648\n"
     ]
    }
   ],
   "source": [
    "# Cell 16 - Train topic classification model\n",
    "topic_texts = []\n",
    "for _, row in raw_data.iterrows():\n",
    "    options_text = ' '.join(row['options']) if row['options'] else ''\n",
    "    full_text = row['question'] + ' ' + options_text\n",
    "    topic_texts.append(full_text)\n",
    "\n",
    "unique_topics = sorted(list(set(topics)))\n",
    "topic_classifier.label_to_id = {label: idx for idx, label in enumerate(unique_topics)}\n",
    "topic_classifier.id_to_label = {idx: label for label, idx in topic_classifier.label_to_id.items()}\n",
    "\n",
    "X_topic = topic_classifier.vectorizer.fit_transform(topic_texts)\n",
    "y_topic = [topic_classifier.label_to_id[topic] for topic in topics]\n",
    "\n",
    "X_train_topic, X_test_topic, y_train_topic, y_test_topic = train_test_split(\n",
    "    X_topic, y_topic, test_size=0.2, random_state=42, stratify=y_topic\n",
    ")\n",
    "\n",
    "topic_classifier.model.fit(X_train_topic, y_train_topic)\n",
    "y_pred_topic = topic_classifier.model.predict(X_test_topic)\n",
    "\n",
    "print(\"üéØ K·∫æT QU·∫¢ TOPIC CLASSIFICATION:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_topic, y_pred_topic):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test_topic, y_pred_topic, average='weighted'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21dcdc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17 - SimilarQuestionFinder Class\n",
    "class SimilarQuestionFinder:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.train_data, self.test_data = train_test_split(\n",
    "            data, test_size=0.2, random_state=42, stratify=data['subject']\n",
    "        )\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=2000, ngram_range=(1, 2), min_df=2, max_df=0.85, sublinear_tf=True\n",
    "        )\n",
    "        \n",
    "        self.question_vectors = None\n",
    "        self._prepare_vectors()\n",
    "    \n",
    "    def _prepare_vectors(self):\n",
    "        train_texts = []\n",
    "        for _, row in self.train_data.iterrows():\n",
    "            full_text = row['question'] + ' ' + ' '.join(row['options']) if row['options'] else row['question']\n",
    "            processed = clean_vietnamese_text(full_text, remove_stopwords=True, normalize=True)\n",
    "            train_texts.append(processed)\n",
    "        \n",
    "        self.vectorizer.fit(train_texts)\n",
    "        \n",
    "        all_texts = []\n",
    "        for _, row in self.data.iterrows():\n",
    "            full_text = row['question'] + ' ' + ' '.join(row['options']) if row['options'] else row['question']\n",
    "            processed = clean_vietnamese_text(full_text, remove_stopwords=True, normalize=True)\n",
    "            all_texts.append(processed)\n",
    "            \n",
    "        self.question_vectors = self.vectorizer.transform(all_texts)\n",
    "    \n",
    "    def find_similar_questions(self, current_question_id, n_similar=3):\n",
    "        try:\n",
    "            current_idx = None\n",
    "            for idx, (_, row) in enumerate(self.data.iterrows()):\n",
    "                if row['id'] == current_question_id:\n",
    "                    current_idx = idx\n",
    "                    break\n",
    "            \n",
    "            if current_idx is None:\n",
    "                return []\n",
    "            \n",
    "            current_vector = self.question_vectors[current_idx]\n",
    "            similarities = cosine_similarity(current_vector, self.question_vectors).flatten()\n",
    "            \n",
    "            similar_questions = []\n",
    "            for idx, similarity in enumerate(similarities):\n",
    "                if idx != current_idx:\n",
    "                    question_data = self.data.iloc[idx]\n",
    "                    similar_questions.append({\n",
    "                        'question_data': question_data,\n",
    "                        'similarity': similarity,\n",
    "                        'index': idx\n",
    "                    })\n",
    "            \n",
    "            similar_questions.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "            return similar_questions[:n_similar]\n",
    "            \n",
    "        except Exception:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831391f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ENHANCED DATASET:\n",
      "Shape: (600, 8)\n",
      "Columns: ['id', 'question', 'options', 'answer', 'subject', 'explanation', 'difficulty', 'topic']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>explanation</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MET_Bio_IE_2019_1</td>\n",
       "      <td>C√≥ th·ªÉ s·ª≠ d·ª•ng h√≥a ch·∫•t n√†o sau ƒë√¢y ƒë·ªÉ ph√°t hi...</td>\n",
       "      <td>[A. Dung d·ªãch NaCl., B. Dung d·ªãch Ca(OH)2., C....</td>\n",
       "      <td>B</td>\n",
       "      <td>biology</td>\n",
       "      <td>C√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng Ca(OH)2 ƒë·ªÉ ph√°t hi·ªán qu√° t...</td>\n",
       "      <td>medium</td>\n",
       "      <td>T·∫ø b√†o h·ªçc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MET_Bio_IE_2019_2</td>\n",
       "      <td>ƒê·ªông v·∫≠t n√†o sau ƒë√¢y trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªù...</td>\n",
       "      <td>[A. Ch√¢u ch·∫•u., B. S∆∞ t·ª≠., C. Chu·ªôt., D. ·∫æch ƒë...</td>\n",
       "      <td>A</td>\n",
       "      <td>biology</td>\n",
       "      <td>Ch√¢u ch·∫•u trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªùng th√¥ng qu...</td>\n",
       "      <td>easy</td>\n",
       "      <td>T·∫ø b√†o h·ªçc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MET_Bio_IE_2019_3</td>\n",
       "      <td>Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ n√†o ...</td>\n",
       "      <td>[A. ADN., B. mARN., C. tARN., D. Pr√¥t√™in.]</td>\n",
       "      <td>D</td>\n",
       "      <td>biology</td>\n",
       "      <td>Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ Pr√¥t...</td>\n",
       "      <td>easy</td>\n",
       "      <td>T·∫ø b√†o h·ªçc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MET_Bio_IE_2019_4</td>\n",
       "      <td>Ph√¢n t·ª≠ n√†o sau ƒë√¢y tr·ª±c ti·∫øp l√†m khu√¥n cho qu...</td>\n",
       "      <td>[A. ADN., B. mARN., C. tARN., D. rARN.]</td>\n",
       "      <td>B</td>\n",
       "      <td>biology</td>\n",
       "      <td>Ph√¢n t·ª≠ mARM tr·ª±c ti·∫øp l√†m khu√¥n cho qu√° tr√¨nh...</td>\n",
       "      <td>medium</td>\n",
       "      <td>T·∫ø b√†o h·ªçc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MET_Bio_IE_2019_5</td>\n",
       "      <td>M·ªôt ph√¢n t·ª≠ ADN ·ªü vi khu·∫©n c√≥ 10% s·ªë nucl√™√¥tit...</td>\n",
       "      <td>[A. 10%., B. 30%., C. 20%., D. 40%.]</td>\n",
       "      <td>D</td>\n",
       "      <td>biology</td>\n",
       "      <td>Theo nguy√™n t·∫Øc b·ªï sung A = T, G = X n√™n %A +%...</td>\n",
       "      <td>medium</td>\n",
       "      <td>T·∫ø b√†o h·ªçc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           question  \\\n",
       "0  MET_Bio_IE_2019_1  C√≥ th·ªÉ s·ª≠ d·ª•ng h√≥a ch·∫•t n√†o sau ƒë√¢y ƒë·ªÉ ph√°t hi...   \n",
       "1  MET_Bio_IE_2019_2  ƒê·ªông v·∫≠t n√†o sau ƒë√¢y trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªù...   \n",
       "2  MET_Bio_IE_2019_3  Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ n√†o ...   \n",
       "3  MET_Bio_IE_2019_4  Ph√¢n t·ª≠ n√†o sau ƒë√¢y tr·ª±c ti·∫øp l√†m khu√¥n cho qu...   \n",
       "4  MET_Bio_IE_2019_5  M·ªôt ph√¢n t·ª≠ ADN ·ªü vi khu·∫©n c√≥ 10% s·ªë nucl√™√¥tit...   \n",
       "\n",
       "                                             options answer  subject  \\\n",
       "0  [A. Dung d·ªãch NaCl., B. Dung d·ªãch Ca(OH)2., C....      B  biology   \n",
       "1  [A. Ch√¢u ch·∫•u., B. S∆∞ t·ª≠., C. Chu·ªôt., D. ·∫æch ƒë...      A  biology   \n",
       "2         [A. ADN., B. mARN., C. tARN., D. Pr√¥t√™in.]      D  biology   \n",
       "3            [A. ADN., B. mARN., C. tARN., D. rARN.]      B  biology   \n",
       "4               [A. 10%., B. 30%., C. 20%., D. 40%.]      D  biology   \n",
       "\n",
       "                                         explanation difficulty       topic  \n",
       "0  C√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng Ca(OH)2 ƒë·ªÉ ph√°t hi·ªán qu√° t...     medium  T·∫ø b√†o h·ªçc  \n",
       "1  Ch√¢u ch·∫•u trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªùng th√¥ng qu...       easy  T·∫ø b√†o h·ªçc  \n",
       "2  Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ Pr√¥t...       easy  T·∫ø b√†o h·ªçc  \n",
       "3  Ph√¢n t·ª≠ mARM tr·ª±c ti·∫øp l√†m khu√¥n cho qu√° tr√¨nh...     medium  T·∫ø b√†o h·ªçc  \n",
       "4  Theo nguy√™n t·∫Øc b·ªï sung A = T, G = X n√™n %A +%...     medium  T·∫ø b√†o h·ªçc  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 18 - Kh·ªüi t·∫°o enhanced dataset\n",
    "data_enhanced = raw_data.copy()\n",
    "data_enhanced['difficulty'] = difficulties\n",
    "data_enhanced['topic'] = topics\n",
    "\n",
    "print(\"üìä ENHANCED DATASET:\")\n",
    "print(f\"Shape: {data_enhanced.shape}\")\n",
    "print(f\"Columns: {data_enhanced.columns.tolist()}\")\n",
    "data_enhanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f6ecb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Similar Question Finder ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o\n",
      "üìä Training data: 480 questions\n",
      "üìä Test data: 120 questions\n",
      "üî§ Vocabulary size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Cell 19 - Kh·ªüi t·∫°o SimilarQuestionFinder\n",
    "similar_finder = SimilarQuestionFinder(data_enhanced)\n",
    "print(\"üîç Similar Question Finder ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o\")\n",
    "print(f\"üìä Training data: {len(similar_finder.train_data)} questions\")\n",
    "print(f\"üìä Test data: {len(similar_finder.test_data)} questions\")\n",
    "print(f\"üî§ Vocabulary size: {len(similar_finder.vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14cd8e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST SIMILARITY V·ªöI SAMPLE QUESTIONS:\n",
      "\n",
      "--- C√¢u 1 ---\n",
      "ID: MET_Bio_IE_2019_1\n",
      "Subject: biology\n",
      "Difficulty: medium\n",
      "Topic: T·∫ø b√†o h·ªçc\n",
      "Question: C√≥ th·ªÉ s·ª≠ d·ª•ng h√≥a ch·∫•t n√†o sau ƒë√¢y ƒë·ªÉ ph√°t hi·ªán qu√° tr√¨nh h√¥ h·∫•p ·ªü th·ª±c v·∫≠t th·∫£...\n",
      "Similar questions:\n",
      "  1. Similarity: 0.381 | Subject: biology | C√¢u 85. Nh√≥m th·ª±c v·∫≠t n√†o sau ƒë√¢y x·∫£y ra qu√° tr√¨nh...\n",
      "  2. Similarity: 0.300 | Subject: biology | C√¢u 109. Khi n√≥i v·ªÅ h√¥ h·∫•p ·ªü th·ª±c v·∫≠t, c√≥ bao nhi√™...\n",
      "\n",
      "--- C√¢u 2 ---\n",
      "ID: MET_Bio_IE_2019_2\n",
      "Subject: biology\n",
      "Difficulty: easy\n",
      "Topic: T·∫ø b√†o h·ªçc\n",
      "Question: ƒê·ªông v·∫≠t n√†o sau ƒë√¢y trao ƒë·ªïi kh√≠ v·ªõi m√¥i tr∆∞·ªùng th√¥ng qua h·ªá th·ªëng ·ªëng kh√≠?...\n",
      "Similar questions:\n",
      "  1. Similarity: 0.616 | Subject: biology | ƒê·ªông v·∫≠t n√†o sau ƒë√¢y h√¥ h·∫•p b·∫±ng h·ªá th·ªëng ·ªëng kh√≠?...\n",
      "  2. Similarity: 0.418 | Subject: biology | C√¢u 95. Sinh v·∫≠t n√†o sau ƒë√¢y c√≥ qu√° tr√¨nh trao ƒë·ªïi...\n",
      "\n",
      "--- C√¢u 3 ---\n",
      "ID: MET_Bio_IE_2019_3\n",
      "Subject: biology\n",
      "Difficulty: easy\n",
      "Topic: T·∫ø b√†o h·ªçc\n",
      "Question: Axit amin l√† ƒë∆°n ph√¢n c·∫•u t·∫°o n√™n ph√¢n t·ª≠ n√†o sau ƒë√¢y?...\n",
      "Similar questions:\n",
      "  1. Similarity: 0.687 | Subject: biology | Trong t·∫ø b√†o, nucl√™√¥tit lo·∫°i timin l√† ƒë∆°n ph√¢n c·∫•u...\n",
      "  2. Similarity: 0.480 | Subject: biology | C√¢u 99. ·ªû sinh v·∫≠t nh√¢n th·ª±c, NST ƒë∆∞·ª£c c·∫•u t·∫°o b·ªüi...\n"
     ]
    }
   ],
   "source": [
    "# Cell 20 - Test similarity v·ªõi sample questions\n",
    "print(\"üß™ TEST SIMILARITY V·ªöI SAMPLE QUESTIONS:\")\n",
    "sample_ids = data_enhanced['id'].head(3).tolist()\n",
    "\n",
    "for i, question_id in enumerate(sample_ids):\n",
    "    current_q = data_enhanced[data_enhanced['id'] == question_id].iloc[0]\n",
    "    print(f\"\\n--- C√¢u {i+1} ---\")\n",
    "    print(f\"ID: {question_id}\")\n",
    "    print(f\"Subject: {current_q['subject']}\")\n",
    "    print(f\"Difficulty: {current_q['difficulty']}\")\n",
    "    print(f\"Topic: {current_q['topic']}\")\n",
    "    print(f\"Question: {current_q['question'][:80]}...\")\n",
    "    \n",
    "    similar_questions = similar_finder.find_similar_questions(question_id, n_similar=2)\n",
    "    if similar_questions:\n",
    "        print(\"Similar questions:\")\n",
    "        for j, similar in enumerate(similar_questions):\n",
    "            sim_q = similar['question_data']\n",
    "            print(f\"  {j+1}. Similarity: {similar['similarity']:.3f} | Subject: {sim_q['subject']} | {sim_q['question'][:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712cc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ƒê√ÅNH GI√Å SIMILARITY PERFORMANCE:\n",
      "Subject Accuracy: 0.9800 (49/50)\n",
      "Within Subject Similarity: 0.4839 ¬± 0.1394\n",
      "Cross Subject Similarity: 0.2409 ¬± 0.0483\n"
     ]
    }
   ],
   "source": [
    "# Cell 21 - Evaluate similarity performance\n",
    "test_sample = similar_finder.test_data.sample(min(50, len(similar_finder.test_data)), random_state=42)\n",
    "same_subject_correct = 0\n",
    "total_tests = 0\n",
    "within_subject_similarity = []\n",
    "cross_subject_similarity = []\n",
    "\n",
    "print(\"üìä ƒê√ÅNH GI√Å SIMILARITY PERFORMANCE:\")\n",
    "\n",
    "for _, test_question in test_sample.iterrows():\n",
    "    similar_questions = similar_finder.find_similar_questions(test_question['id'], n_similar=3)\n",
    "    \n",
    "    if similar_questions:\n",
    "        most_similar = similar_questions[0]\n",
    "        if most_similar['question_data']['subject'] == test_question['subject']:\n",
    "            same_subject_correct += 1\n",
    "        \n",
    "        for similar in similar_questions:\n",
    "            sim_score = similar['similarity']\n",
    "            if similar['question_data']['subject'] == test_question['subject']:\n",
    "                within_subject_similarity.append(sim_score)\n",
    "            else:\n",
    "                cross_subject_similarity.append(sim_score)\n",
    "        \n",
    "        total_tests += 1\n",
    "\n",
    "subject_accuracy = same_subject_correct / total_tests if total_tests > 0 else 0\n",
    "print(f\"Subject Accuracy: {subject_accuracy:.4f} ({same_subject_correct}/{total_tests})\")\n",
    "\n",
    "if within_subject_similarity:\n",
    "    print(f\"Within Subject Similarity: {np.mean(within_subject_similarity):.4f} ¬± {np.std(within_subject_similarity):.4f}\")\n",
    "if cross_subject_similarity:\n",
    "    print(f\"Cross Subject Similarity: {np.mean(cross_subject_similarity):.4f} ¬± {np.std(cross_subject_similarity):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29a1b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utility functions ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a\n"
     ]
    }
   ],
   "source": [
    "# Cell 22 - Utility functions cho quiz\n",
    "def get_random_question(data, subject=None, year=None, difficulty=None, topic=None):\n",
    "    filtered_data = data.copy()\n",
    "    \n",
    "    if subject:\n",
    "        filtered_data = filtered_data[filtered_data['subject'] == subject]\n",
    "    if year:\n",
    "        filtered_data = filtered_data[filtered_data['id'].str.contains(str(year), na=False)]\n",
    "    if difficulty and 'difficulty' in filtered_data.columns:\n",
    "        filtered_data = filtered_data[filtered_data['difficulty'] == difficulty]\n",
    "    if topic and 'topic' in filtered_data.columns:\n",
    "        filtered_data = filtered_data[filtered_data['topic'] == topic]\n",
    "    \n",
    "    if len(filtered_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    return filtered_data.sample(1).iloc[0]\n",
    "\n",
    "def check_answer(user_answer, correct_answer):\n",
    "    return user_answer.upper().strip() == correct_answer.upper().strip()\n",
    "\n",
    "print(\"‚úÖ Utility functions ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfda0537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç TEST FILTER FUNCTIONALITY:\n",
      "\n",
      "Test 1: {'subject': 'physics', 'difficulty': 'easy'}\n",
      "  ‚úÖ Found: physics | easy | C∆° h·ªçc\n",
      "  Question: C√¢u 17. Khi n√≥i v·ªÅ thuy·∫øt l∆∞·ª£ng t·ª≠ √°nh s√°ng, ph√°t bi·ªÉu n√†o s...\n",
      "\n",
      "Test 2: {'subject': 'chemistry', 'topic': 'H√≥a h·ªØu c∆°'}\n",
      "  ‚úÖ Found: chemistry | hard | H√≥a h·ªØu c∆°\n",
      "  Question: Th√†nh ph·∫ßn ch√≠nh c·ªßa ƒë√° v√¥i l√† canxi cacbonat. C√¥ng th·ª©c c·ªßa...\n",
      "\n",
      "Test 3: {'difficulty': 'hard'}\n",
      "  ‚úÖ Found: chemistry | hard | H√≥a h·ªØu c∆°\n",
      "  Question: ƒê·ªÉ ${m}$ gam h·ªón h·ª£p ${E}$ g·ªìm ${Al}$, ${Fe}$ v√† ${Cu}$ tron...\n",
      "\n",
      "Test 4: {'subject': 'biology', 'difficulty': 'medium'}\n",
      "  ‚úÖ Found: biology | medium | T·∫ø b√†o h·ªçc\n",
      "  Question: M·ªôt lo√†i th·ª±c v·∫≠t, x√©t 2 c·∫∑p NST k√≠ hi·ªáu l√† A, a v√† B, b. C∆°...\n"
     ]
    }
   ],
   "source": [
    "# Cell 23 - Test filter functionality\n",
    "print(\"üîç TEST FILTER FUNCTIONALITY:\")\n",
    "\n",
    "filter_tests = [\n",
    "    {'subject': 'physics', 'difficulty': 'easy'},\n",
    "    {'subject': 'chemistry', 'topic': 'H√≥a h·ªØu c∆°'},\n",
    "    {'difficulty': 'hard'},\n",
    "    {'subject': 'biology', 'difficulty': 'medium'}\n",
    "]\n",
    "\n",
    "for i, filters in enumerate(filter_tests):\n",
    "    print(f\"\\nTest {i+1}: {filters}\")\n",
    "    question = get_random_question(data_enhanced, **filters)\n",
    "    if question is not None:\n",
    "        print(f\"  ‚úÖ Found: {question['subject']} | {question['difficulty']} | {question['topic']}\")\n",
    "        print(f\"  Question: {question['question'][:60]}...\")\n",
    "    else:\n",
    "        print(\"  ‚ùå No questions found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f79ef5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéÆ DEMO QUIZ FLOW:\n",
      "üìù C√¢u h·ªèi ID: MET_Phy_IE_2019_17\n",
      "üìö M√¥n: physics\n",
      "‚≠ê ƒê·ªô kh√≥: hard\n",
      "üìñ Ch·ªß ƒë·ªÅ: C∆° h·ªçc\n",
      "\n",
      "‚ùì C√¢u h·ªèi: C√¢u 17. ƒê·∫∑t ƒëi·ªán √°p u = 200*cos (100*\\pi*t) (V) v√†o hai ƒë·∫ßu ƒëo·∫°n m·∫°ch g·ªìm ƒëi·ªán tr·ªü 100 Ohm, cu·ªôn c·∫£m thu·∫ßn v√† t·ª• ƒëi·ªán m·∫Øc n·ªëi ti·∫øp. Bi·∫øt trong ƒëo·∫°n m·∫°ch c√≥ c·ªông h∆∞·ªüng ƒëi·ªán. C∆∞·ªùng ƒë·ªô hi·ªáu d·ª•ng c·ªßa d√≤ng ƒëi·ªán trong ƒëo·∫°n m·∫°ch l√†\n",
      "\n",
      "üìã C√°c ƒë√°p √°n:\n",
      "  A. 2\\sqrt{2} A.\n",
      "  B. \\sqrt{2} A.\n",
      "  C. 2 A.\n",
      "  D. 1 A.\n",
      "\n",
      "‚úÖ ƒê√°p √°n ƒë√∫ng: B\n"
     ]
    }
   ],
   "source": [
    "# Cell 24 - Demo quiz flow\n",
    "print(\"üéÆ DEMO QUIZ FLOW:\")\n",
    "\n",
    "# Get random question\n",
    "current_question = get_random_question(data_enhanced, subject='physics')\n",
    "if current_question is not None:\n",
    "    print(f\"üìù C√¢u h·ªèi ID: {current_question['id']}\")\n",
    "    print(f\"üìö M√¥n: {current_question['subject']}\")\n",
    "    print(f\"‚≠ê ƒê·ªô kh√≥: {current_question['difficulty']}\")\n",
    "    print(f\"üìñ Ch·ªß ƒë·ªÅ: {current_question['topic']}\")\n",
    "    print(f\"\\n‚ùì C√¢u h·ªèi: {current_question['question']}\")\n",
    "    print(f\"\\nüìã C√°c ƒë√°p √°n:\")\n",
    "    for option in current_question['options']:\n",
    "        print(f\"  {option}\")\n",
    "    print(f\"\\n‚úÖ ƒê√°p √°n ƒë√∫ng: {current_question['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "febce837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ TEST ANSWER CHECKING:\n",
      "Correct answer: B\n",
      "User answer 'A': ‚ùå Sai\n",
      "User answer 'B': ‚úÖ ƒê√∫ng\n",
      "User answer 'C': ‚ùå Sai\n",
      "User answer 'D': ‚ùå Sai\n"
     ]
    }
   ],
   "source": [
    "# Cell 25 - Test answer checking\n",
    "user_answers = ['A', 'B', 'C', 'D']\n",
    "correct_answer = current_question['answer']\n",
    "\n",
    "print(f\"\\nüß™ TEST ANSWER CHECKING:\")\n",
    "print(f\"Correct answer: {correct_answer}\")\n",
    "\n",
    "for answer in user_answers:\n",
    "    is_correct = check_answer(answer, correct_answer)\n",
    "    result = \"‚úÖ ƒê√∫ng\" if is_correct else \"‚ùå Sai\"\n",
    "    print(f\"User answer '{answer}': {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f400e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç T√åM C√ÇU H·ªéI T∆Ø∆†NG T·ª∞:\n",
      "T√¨m th·∫•y 3 c√¢u h·ªèi t∆∞∆°ng t·ª±:\n",
      "\n",
      "1. ƒê·ªô t∆∞∆°ng ƒë·ªìng: 0.630\n",
      "   Subject: physics | Difficulty: hard | Topic: ƒêi·ªán xoay chi·ªÅu\n",
      "   Question: C√¢u 36. ƒê·∫∑t ƒëi·ªán √°p xoay chi·ªÅu u = 60*\\sqrt {2}*cos(100*\\pi*t) (V) (t t√≠nh b·∫±ng ...\n",
      "   Answer: A\n",
      "\n",
      "2. ƒê·ªô t∆∞∆°ng ƒë·ªìng: 0.615\n",
      "   Subject: physics | Difficulty: hard | Topic: C∆° h·ªçc\n",
      "   Question: C√¢u 39. Cho ƒëo·∫°n m·∫°ch AB g·ªìm cu·ªôn c·∫£m thu·∫ßn L, ƒëi·ªán tr·ªü R = 50 Ohm v√† t·ª• ƒëi·ªán m·∫Ø...\n",
      "   Answer: D\n",
      "\n",
      "3. ƒê·ªô t∆∞∆°ng ƒë·ªìng: 0.603\n",
      "   Subject: physics | Difficulty: hard | Topic: ƒêi·ªán xoay chi·ªÅu\n",
      "   Question: ƒê·∫∑t ƒëi·ªán √°p xoay chi·ªÅu u = U\\sqrt {2}cos (\\omega t) (\\omega>0) v√†o hai ƒë·∫ßu m·ªôt ƒë...\n",
      "   Answer: C\n"
     ]
    }
   ],
   "source": [
    "# Cell 26 - Test similar questions cho demo question\n",
    "print(f\"\\nüîç T√åM C√ÇU H·ªéI T∆Ø∆†NG T·ª∞:\")\n",
    "similar_questions = similar_finder.find_similar_questions(current_question['id'], n_similar=3)\n",
    "\n",
    "if similar_questions:\n",
    "    print(f\"T√¨m th·∫•y {len(similar_questions)} c√¢u h·ªèi t∆∞∆°ng t·ª±:\")\n",
    "    for i, similar in enumerate(similar_questions, 1):\n",
    "        similar_q = similar['question_data']\n",
    "        similarity_score = similar['similarity']\n",
    "        \n",
    "        print(f\"\\n{i}. ƒê·ªô t∆∞∆°ng ƒë·ªìng: {similarity_score:.3f}\")\n",
    "        print(f\"   Subject: {similar_q['subject']} | Difficulty: {similar_q['difficulty']} | Topic: {similar_q['topic']}\")\n",
    "        print(f\"   Question: {similar_q['question'][:80]}...\")\n",
    "        print(f\"   Answer: {similar_q['answer']}\")\n",
    "else:\n",
    "    print(\"‚ùå Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi t∆∞∆°ng t·ª±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b411c428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DEMO SCORE TRACKING:\n",
      "C√¢u 1: ‚úÖ | Score: 1/1 (100.0%)\n",
      "C√¢u 2: ‚ùå | Score: 1/2 (50.0%)\n",
      "C√¢u 3: ‚úÖ | Score: 2/3 (66.7%)\n",
      "C√¢u 4: ‚úÖ | Score: 3/4 (75.0%)\n",
      "C√¢u 5: ‚ùå | Score: 3/5 (60.0%)\n",
      "C√¢u 6: ‚úÖ | Score: 4/6 (66.7%)\n",
      "C√¢u 7: ‚ùå | Score: 4/7 (57.1%)\n",
      "C√¢u 8: ‚úÖ | Score: 5/8 (62.5%)\n",
      "C√¢u 9: ‚úÖ | Score: 6/9 (66.7%)\n",
      "C√¢u 10: ‚ùå | Score: 6/10 (60.0%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 27 - Score tracking demo\n",
    "score_tracker = ScoreTracker()\n",
    "print(\"üìä DEMO SCORE TRACKING:\")\n",
    "\n",
    "# Simulate some answers\n",
    "test_results = [True, False, True, True, False, True, False, True, True, False]\n",
    "\n",
    "for i, result in enumerate(test_results, 1):\n",
    "    score_tracker.add_result(result)\n",
    "    print(f\"C√¢u {i}: {'‚úÖ' if result else '‚ùå'} | Score: {score_tracker.correct}/{score_tracker.total} ({score_tracker.get_accuracy():.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3befdcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà TH·ªêNG K√ä T·ªîNG QUAN H·ªÜ TH·ªêNG:\n",
      "üìä T·ªïng c√¢u h·ªèi: 600\n",
      "üìö S·ªë m√¥n h·ªçc: 3\n",
      "‚≠ê S·ªë m·ª©c ƒë·ªô kh√≥: 3\n",
      "üìñ S·ªë ch·ªß ƒë·ªÅ: 6\n",
      "\n",
      "üìä Ph√¢n ph·ªëi m√¥n h·ªçc:\n",
      "subject\n",
      "biology      200\n",
      "chemistry    200\n",
      "physics      200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚≠ê Ph√¢n ph·ªëi ƒë·ªô kh√≥:\n",
      "difficulty\n",
      "hard      282\n",
      "medium    202\n",
      "easy      116\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìñ Top 10 ch·ªß ƒë·ªÅ ph·ªï bi·∫øn:\n",
      "topic\n",
      "H√≥a h·ªØu c∆°         200\n",
      "C∆° h·ªçc             103\n",
      "T·∫ø b√†o h·ªçc         100\n",
      "Di truy·ªÅn h·ªçc      100\n",
      "Dao ƒë·ªông c∆°         72\n",
      "ƒêi·ªán xoay chi·ªÅu     25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 28 - Statistics summary\n",
    "print(\"üìà TH·ªêNG K√ä T·ªîNG QUAN H·ªÜ TH·ªêNG:\")\n",
    "print(f\"üìä T·ªïng c√¢u h·ªèi: {len(data_enhanced)}\")\n",
    "print(f\"üìö S·ªë m√¥n h·ªçc: {data_enhanced['subject'].nunique()}\")\n",
    "print(f\"‚≠ê S·ªë m·ª©c ƒë·ªô kh√≥: {data_enhanced['difficulty'].nunique()}\")\n",
    "print(f\"üìñ S·ªë ch·ªß ƒë·ªÅ: {data_enhanced['topic'].nunique()}\")\n",
    "\n",
    "print(f\"\\nüìä Ph√¢n ph·ªëi m√¥n h·ªçc:\")\n",
    "print(data_enhanced['subject'].value_counts())\n",
    "\n",
    "print(f\"\\n‚≠ê Ph√¢n ph·ªëi ƒë·ªô kh√≥:\")\n",
    "print(data_enhanced['difficulty'].value_counts())\n",
    "\n",
    "print(f\"\\nüìñ Top 10 ch·ªß ƒë·ªÅ ph·ªï bi·∫øn:\")\n",
    "print(data_enhanced['topic'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2682c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ T·ªîNG K·∫æT PERFORMANCE C√ÅC MODEL:\n",
      "\n",
      "üéØ DIFFICULTY CLASSIFIER:\n",
      "  - Algorithm: Random Forest + TF-IDF\n",
      "  - Features: 15 NLP features + text vectorization\n",
      "  - Classes: ['hard', 'medium', 'easy']\n",
      "  - Test Accuracy: 0.6583\n",
      "  - F1-Score (weighted): 0.6199\n",
      "\n",
      "üè∑Ô∏è TOPIC CLASSIFIER:\n",
      "  - Algorithm: Random Forest + TF-IDF\n",
      "  - Topics per subject: Physics(8), Chemistry(8), Biology(8)\n",
      "  - Total unique topics: 6\n",
      "  - Test Accuracy: 0.8667\n",
      "  - F1-Score (weighted): 0.8648\n",
      "\n",
      "üîç SIMILAR QUESTION FINDER:\n",
      "  - Algorithm: TF-IDF + Cosine Similarity\n",
      "  - Vocabulary size: 2000\n",
      "  - Subject accuracy: 0.9800\n",
      "  - Within-subject similarity: 0.4839\n",
      "  - Cross-subject similarity: 0.2409\n"
     ]
    }
   ],
   "source": [
    "# Cell 29 - Model performance summary\n",
    "print(\"ü§ñ T·ªîNG K·∫æT PERFORMANCE C√ÅC MODEL:\")\n",
    "\n",
    "print(f\"\\nüéØ DIFFICULTY CLASSIFIER:\")\n",
    "print(f\"  - Algorithm: Random Forest + TF-IDF\")\n",
    "print(f\"  - Features: 15 NLP features + text vectorization\")\n",
    "print(f\"  - Classes: {difficulty_counts.index.tolist()}\")\n",
    "print(f\"  - Test Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"  - F1-Score (weighted): {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è TOPIC CLASSIFIER:\")\n",
    "print(f\"  - Algorithm: Random Forest + TF-IDF\")\n",
    "print(f\"  - Topics per subject: Physics({len(topic_classifier.subject_topics['physics'])}), Chemistry({len(topic_classifier.subject_topics['chemistry'])}), Biology({len(topic_classifier.subject_topics['biology'])})\")\n",
    "print(f\"  - Total unique topics: {len(unique_topics)}\")\n",
    "print(f\"  - Test Accuracy: {accuracy_score(y_test_topic, y_pred_topic):.4f}\")\n",
    "print(f\"  - F1-Score (weighted): {f1_score(y_test_topic, y_pred_topic, average='weighted'):.4f}\")\n",
    "\n",
    "print(f\"\\nüîç SIMILAR QUESTION FINDER:\")\n",
    "print(f\"  - Algorithm: TF-IDF + Cosine Similarity\")\n",
    "print(f\"  - Vocabulary size: {len(similar_finder.vectorizer.vocabulary_)}\")\n",
    "print(f\"  - Subject accuracy: {subject_accuracy:.4f}\")\n",
    "if within_subject_similarity:\n",
    "    print(f\"  - Within-subject similarity: {np.mean(within_subject_similarity):.4f}\")\n",
    "if cross_subject_similarity:\n",
    "    print(f\"  - Cross-subject similarity: {np.mean(cross_subject_similarity):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4b4e386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ KI·ªÇM TRA S·∫¥N S√ÄNG H·ªÜ TH·ªêNG:\n",
      "‚úÖ Data loaded\n",
      "‚úÖ Difficulty labels created\n",
      "‚úÖ Topic labels created\n",
      "‚úÖ Difficulty model trained\n",
      "‚úÖ Topic model trained\n",
      "‚úÖ Similar finder ready\n",
      "‚úÖ Enhanced dataset ready\n",
      "‚úÖ Filter functions work\n",
      "‚úÖ Answer checking works\n",
      "‚úÖ Score tracking works\n",
      "\n",
      "üéâ H·ªÜ TH·ªêNG S·∫¥N S√ÄNG!\n",
      "\n",
      "üöÄ C√≥ th·ªÉ ch·∫°y Streamlit app v·ªõi l·ªánh:\n",
      "streamlit run main.py\n"
     ]
    }
   ],
   "source": [
    "# Cell 30 - System readiness check\n",
    "print(\"‚úÖ KI·ªÇM TRA S·∫¥N S√ÄNG H·ªÜ TH·ªêNG:\")\n",
    "\n",
    "checks = [\n",
    "    (\"Data loaded\", len(data_enhanced) > 0),\n",
    "    (\"Difficulty labels created\", len(difficulties) == len(data_enhanced)),\n",
    "    (\"Topic labels created\", len(topics) == len(data_enhanced)),\n",
    "    (\"Difficulty model trained\", difficulty_classifier.model is not None),\n",
    "    (\"Topic model trained\", topic_classifier.model is not None),\n",
    "    (\"Similar finder ready\", similar_finder.question_vectors is not None),\n",
    "    (\"Enhanced dataset ready\", 'difficulty' in data_enhanced.columns and 'topic' in data_enhanced.columns),\n",
    "    (\"Filter functions work\", get_random_question(data_enhanced) is not None),\n",
    "    (\"Answer checking works\", check_answer('A', 'A') == True),\n",
    "    (\"Score tracking works\", score_tracker.get_accuracy() > 0)\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for check_name, passed in checks:\n",
    "    status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "    print(f\"{status} {check_name}\")\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print(f\"\\n{'üéâ H·ªÜ TH·ªêNG S·∫¥N S√ÄNG!' if all_passed else '‚ö†Ô∏è C√ì L·ªñI C·∫¶N KH·∫ÆC PH·ª§C!'}\")\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\nüöÄ C√≥ th·ªÉ ch·∫°y Streamlit app v·ªõi l·ªánh:\")\n",
    "    print(\"streamlit run main.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
